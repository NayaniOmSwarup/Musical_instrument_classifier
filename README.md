# ğŸ§ Audio Classification with Transfer Learning (VGG16 & EfficientNet)

This project applies **transfer learning** to perform **audio classification** by converting audio signals into spectrogram images and leveraging **pretrained CNNs** like **VGG16** and **EfficientNetB1**.

By treating spectrograms as 2D images, we can utilize the power of **deep computer vision models** for robust **audio pattern recognition**.

---

## ğŸ§  What This Project Does

* ğŸ“¦ Loads a custom audio dataset (`net_audio.zip`)
* ğŸ”„ Converts `.wav` files into **Mel-spectrogram images**
* âš™ï¸ Fine-tunes pretrained models (VGG16, EfficientNetB1) for classification
* ğŸ“ˆ Evaluates accuracy, precision, recall, and visualizes confusion matrix
* ğŸ“Š Compares model performance using classification reports

---

## ğŸ§± Architecture Summary

```text
Audio Files (.wav)
   â†“
Librosa + Matplotlib
   â†“
Mel-Spectrogram Images (Saved as PNG/JPG)
   â†“
Image Preprocessing (Resize, Normalize)
   â†“
Pretrained CNN (VGG16 or EfficientNetB1)
   â†“
Dense Layer + Softmax
   â†“
Predicted Class
```

---

## ğŸ—‚ï¸ Dataset

The dataset is a zipped folder `net_audio.zip` containing subfolders for each class of audio files.

Example structure:

```
net_audio/
â”œâ”€â”€ airplane/
â”‚   â”œâ”€â”€ a1.wav
â”‚   â””â”€â”€ ...
â”œâ”€â”€ car_horn/
â”œâ”€â”€ dog_bark/
â”œâ”€â”€ siren/
â””â”€â”€ ...
```

> âœ… The dataset is mounted from **Google Drive** and extracted into `/content/net_audio`.

---

## ğŸ§ª Spectrogram Generation

Mel-spectrograms are generated using **Librosa**, with each `.wav` converted into a **log-magnitude mel scale** image.

Example code:

```python
y, sr = librosa.load(file_path)
mel_spec = librosa.feature.melspectrogram(y=y, sr=sr)
log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)
```

These are saved using `matplotlib.pyplot.imsave()` for use with CNNs.

---

## ğŸ§  Model Architecture

### VGG16

* Pretrained on ImageNet
* Top layers removed
* New dense layers added:

  * Flatten â†’ Dense(256) â†’ Dropout(0.5) â†’ Dense(#classes)

### EfficientNetB1

* Lightweight, optimized CNN
* Pretrained weights from ImageNet
* Modified top layers:

  * GlobalAveragePooling â†’ Dense â†’ Dropout â†’ Output Layer

---

## ğŸ Training Pipeline

1. Convert all audio files into spectrograms.
2. Split dataset into **train** and **test** using `train_test_split()`.
3. Encode labels using `LabelEncoder`.
4. Load images into numpy arrays for training.
5. Fine-tune VGG16 and EfficientNetB1 on spectrogram dataset.
6. Evaluate performance using `classification_report()` and `confusion_matrix()`.

---

## ğŸ“ˆ Results

* Both models reach **high classification accuracy**.
* Confusion matrices and classification reports show strong separation between audio classes.
* EfficientNetB1 performs better in terms of parameter efficiency.

---

## ğŸ“Š Visualizations

* Mel-spectrogram plots for sample audio files.
* Training loss and accuracy graphs (if training history is saved).
* Confusion matrix heatmaps using `seaborn.heatmap()`.

---

## âš™ï¸ Dependencies

```bash
pip install librosa matplotlib numpy seaborn scikit-learn tensorflow keras
```

Or in Colab:

```python
import librosa, keras, sklearn, matplotlib, seaborn
```

---

## ğŸš€ How to Run

1. Upload your audio dataset to Google Drive.
2. Mount Google Drive:

```python
from google.colab import drive
drive.mount('/content/drive')
```

3. Unzip the dataset:

```python
!unzip -q "/content/drive/My Drive/net_audio.zip" -d /content/net_audio
```

4. Run the notebook cells to generate spectrograms, train models, and evaluate.

---

## ğŸ“Œ Notes

* Models are trained on a **small custom dataset**, so performance may vary.
* You can experiment with **other pretrained models** like ResNet, MobileNet, etc.
* Optionally, use **data augmentation** (e.g. time-shifting, pitch shifting) before spectrogram generation.

## EfficientNetB1 
<img width="633" height="618" alt="image" src="https://github.com/user-attachments/assets/ff59caa6-34bd-4636-b984-edfd5d5c3cbe" />
## VGG16 
<img width="655" height="596" alt="image" src="https://github.com/user-attachments/assets/2032bbbf-7db4-4305-8483-7e05aa579f7a" />
## CNN-LSTM Model
<img width="1124" height="539" alt="image" src="https://github.com/user-attachments/assets/91c90991-77e1-4e1c-83b6-c76e2441b8bc" />



